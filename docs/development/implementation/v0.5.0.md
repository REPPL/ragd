# v0.5.0 Implementation Record

## Overview

Conversational interface with local LLM integration, transforming ragd from a retrieval tool into a conversational knowledge assistant.

## Features Implemented

### F-020: Ollama LLM Integration

**Modules:**
- `src/ragd/llm/ollama.py` - OllamaClient with streaming support
- `src/ragd/llm/models.py` - Multi-model orchestration
- `src/ragd/chat/session.py` - Chat session management

**Key Components:**
- `OllamaClient` - HTTP client for Ollama API
- `StreamChunk` - Streaming response chunks
- `LLMResponse` - Complete response wrapper
- `ChatSession` - Session with history and context

### F-055: Multi-Model Orchestration

**Modules:**
- `src/ragd/llm/models.py` - Model registry and router

**Key Components:**
- `ModelInfo` - Model metadata (size, quantisation, family)
- `ModelRegistry` - Lists and caches available models
- `ModelRouter` - Routes tasks to appropriate models
- `ModelsConfig` - Configuration for model selection
- `TaskType` - Task categorisation (default, complex, simple)

### F-014: Agentic RAG

**Modules:**
- `src/ragd/chat/agentic.py` - CRAG and Self-RAG implementation

**Key Components:**
- `AgenticRAG` - Main agentic RAG class
- `AgenticConfig` - Configuration for CRAG/Self-RAG
- `AgenticResponse` - Response with confidence scores
- `RetrievalQuality` - Quality assessment enum

**CRAG (Corrective RAG):**
- Relevance evaluation prompts
- Query rewriting when retrieval is poor
- Configurable relevance threshold

**Self-RAG:**
- Faithfulness evaluation
- Response refinement
- Configurable faithfulness threshold

### F-013: RAGAS Evaluation

**Modules:**
- `src/ragd/evaluation/metrics.py` - Evaluation metrics
- `src/ragd/evaluation/evaluator.py` - Evaluation engine
- `src/ragd/evaluation/storage.py` - Result persistence

**Key Components:**
- `EvaluationMetrics` - Context precision, recall, relevance
- `Evaluator` - Query evaluation orchestrator
- `EvaluationResult` - Single query result
- `EvaluationReport` - Batch evaluation report
- `EvaluationStorage` - JSON-based history storage

**Metrics Implemented:**
- Context Precision (retrieval quality)
- Context Recall (ground truth comparison)
- Relevance Score (position-weighted)
- NDCG (ranking quality)
- Reciprocal Rank (first relevant position)

## CLI Commands

### New Commands

```bash
# Ask a question
ragd ask "What is machine learning?"

# Ask with agentic mode
ragd ask "Summarise the security policy" --agentic --show-confidence

# Interactive chat
ragd chat
ragd chat --model llama3.2:8b
ragd chat --session abc123  # Resume session

# List available models
ragd models list

# Evaluate retrieval quality
ragd evaluate --query "What is Python?"
ragd evaluate --test-file queries.yaml
```

### Command Options

**ask:**
- `--model` - Override LLM model
- `--temperature` - Sampling temperature
- `--agentic/--no-agentic` - Enable/disable agentic RAG
- `--show-confidence` - Display confidence scores
- `--cite` - Citation style (none, numbered, inline)

**chat:**
- `--model` - Override LLM model
- `--session` - Resume previous session
- `/exit`, `/help`, `/clear`, `/history` - Chat commands

**evaluate:**
- `--query` - Single query to evaluate
- `--test-file` - YAML/JSON batch file
- `--threshold` - Relevance threshold
- `--no-save` - Skip saving results

## Architecture

### Chat Module Structure

```
src/ragd/chat/
├── __init__.py      # Module exports
├── agentic.py       # AgenticRAG (CRAG + Self-RAG)
├── context.py       # ContextWindow management
├── history.py       # ChatHistory persistence
├── message.py       # ChatMessage, CitedAnswer
├── prompts.py       # RAG prompt templates
└── session.py       # ChatSession orchestration
```

### LLM Module Structure

```
src/ragd/llm/
├── __init__.py      # Module exports
├── client.py        # Base LLM client (abstract)
├── models.py        # ModelRegistry, ModelRouter
└── ollama.py        # OllamaClient implementation
```

### Evaluation Module Structure

```
src/ragd/evaluation/
├── __init__.py      # Module exports
├── evaluator.py     # Evaluator, EvaluationResult
├── metrics.py       # Metric calculations
└── storage.py       # Result persistence
```

## Testing

- `tests/test_chat.py` - 36 chat module tests
- `tests/test_models.py` - 27 model orchestration tests
- `tests/test_agentic.py` - 31 agentic RAG tests
- `tests/test_evaluation.py` - 42 evaluation tests

**Total: 136 new tests for v0.5.0**

## Dependencies

- Ollama (external) - Required for LLM generation
- No new Python dependencies added

## Configuration

New `llm` section in config:

```yaml
llm:
  base_url: "http://localhost:11434"
  model: "llama3.2:3b"
  timeout: 120
```

## Performance

- Streaming responses for real-time output
- Model caching in registry (30-second TTL)
- Context window token estimation
- Position-weighted search result scoring

---

**Status**: Complete
