# ragd Configuration Reference
# =============================
#
# Default configuration file location: ~/.config/ragd/config.yaml
#
# Configuration precedence (highest to lowest):
#   1. CLI flags (--config, --verbose, etc.)
#   2. Environment variables (RAGD_*)
#   3. Configuration file (this file)
#   4. Built-in defaults
#
# Environment variable format: RAGD_SECTION__KEY (double underscore for nesting)
# Example: RAGD_EMBEDDING__MODEL=all-MiniLM-L6-v2

# ============================================================================
# REQUIRED: Schema version for migration support
# ============================================================================
version: 1

# ============================================================================
# Storage Configuration
# ============================================================================
# Paths follow XDG Base Directory Specification
# https://specifications.freedesktop.org/basedir/latest/
storage:
  # Configuration directory (XDG_CONFIG_HOME)
  config_dir: ~/.config/ragd

  # Data directory for database and documents (XDG_DATA_HOME)
  data_dir: ~/.local/share/ragd

  # Cache directory for embeddings and temp files (XDG_CACHE_HOME)
  cache_dir: ~/.cache/ragd

  # ChromaDB persistent storage location
  chroma_db: ~/.local/share/ragd/chroma_db

# ============================================================================
# Embedding Configuration
# ============================================================================
embedding:
  # Model identifier (Hugging Face model name)
  # Recommended: BAAI/bge-base-en-v1.5 (best accuracy/speed balance)
  # Alternative: sentence-transformers/all-MiniLM-L6-v2 (faster, less accurate)
  model: BAAI/bge-base-en-v1.5

  # Compute device
  # Options: auto | cpu | cuda | mps | cuda:0
  # "auto" selects: MPS (Apple Silicon) > CUDA (NVIDIA) > CPU
  device: auto

  # Normalise embeddings for cosine similarity
  # IMPORTANT: Must be true for BGE and E5 models
  normalize: true

  # Batch size for embedding generation
  # Scale based on available memory:
  #   - minimal tier: 8
  #   - standard tier: 16
  #   - high tier: 32
  #   - extreme tier: 64
  batch_size: 32

  # Query prefix (required for BGE models)
  # Leave empty for models that don't require prefixes
  query_prefix: "Represent this sentence for searching relevant passages: "

# ============================================================================
# Chunking Configuration
# ============================================================================
chunking:
  # Chunking strategy
  # Options: sentence | recursive | fixed
  #   - sentence: Split on sentence boundaries (recommended for prose)
  #   - recursive: Split on headers, paragraphs, sentences (for structured docs)
  #   - fixed: Fixed-size chunks (fallback)
  strategy: sentence

  # Target chunk size in tokens
  # Research optimal: 400-512 tokens for general RAG
  target_tokens: 512

  # Maximum chunk size (hard limit)
  # Should not exceed embedding model max sequence length
  max_tokens: 768

  # Minimum chunk size (skip smaller chunks)
  min_tokens: 50

  # Overlap between consecutive chunks
  # Recommended: 10-20% of target_tokens
  # Preserves context at chunk boundaries
  overlap_tokens: 50

# ============================================================================
# Document Formats
# ============================================================================
formats:
  # Enable/disable format support
  pdf: true
  txt: true
  markdown: true

  # PDF processing options
  pdf_options:
    # Quality routing for complex PDFs (ADR-0019)
    # Options: auto | fast | quality
    #   - auto: Detect and route (simple→fast, complex→quality)
    #   - fast: PyMuPDF4LLM only (faster, less accurate for complex PDFs)
    #   - quality: Docling always (slower, better for complex layouts)
    quality_routing: auto

    # Extract images (v0.2+)
    extract_images: false

# ============================================================================
# Search Configuration
# ============================================================================
search:
  # Default number of results
  default_limit: 10

  # Maximum results allowed
  max_limit: 100

  # Minimum similarity threshold (0.0 - 1.0)
  # Results below this score are filtered out
  min_threshold: 0.0

# ============================================================================
# Output Configuration
# ============================================================================
output:
  # Default output format
  # Options: rich | plain | json
  # "rich" auto-detects pipes and switches to "plain"
  default_format: rich

  # Colour scheme for rich output
  # Options: auto | dark | light | none
  color_scheme: auto

  # Respect NO_COLOR environment variable
  respect_no_color: true

# ============================================================================
# Logging Configuration
# ============================================================================
logging:
  # Log level
  # Options: DEBUG | INFO | WARNING | ERROR
  level: INFO

  # Log file location (null to disable file logging)
  file: ~/.local/state/ragd/logs/ragd.log

  # Maximum log file size in MB (rotates when exceeded)
  max_size_mb: 10

  # Number of backup log files to keep
  backup_count: 5

# ============================================================================
# Hardware Configuration (auto-detected by ragd init)
# ============================================================================
# These values are typically set automatically during ragd init
# and can be used to override auto-detection
#
# hardware:
#   # Hardware tier affects default settings
#   # Options: minimal | standard | high | extreme
#   tier: high
#
#   # Compute backend
#   # Options: cpu | cuda | mps
#   backend: mps
#
#   # Available memory in GB (for batch size tuning)
#   memory_gb: 32.0
#
#   # Timestamp of hardware detection
#   detected_at: 2025-01-26T10:30:00Z

# ============================================================================
# Agentic RAG Parameters (v1.0.5)
# ============================================================================
# Controls CRAG (Corrective RAG) and Self-RAG behaviour
agentic_params:
  # Thresholds for quality evaluation
  relevance_threshold: 0.6      # Minimum score for relevant context
  faithfulness_threshold: 0.7   # Minimum score for faithful answer
  excellent_threshold: 0.8      # Score for "excellent" quality
  good_threshold: 0.6           # Score for "good" quality
  poor_threshold: 0.4           # Score for "poor" quality

  # LLM parameters per operation
  relevance_eval:
    temperature: 0.0            # Deterministic evaluation
    max_tokens: 10              # Short score response
  query_rewrite:
    temperature: 0.3            # Some creativity for rewrites
    max_tokens: 100             # Query length limit
  answer_generation:
    temperature: 0.7            # Default creativity
    max_tokens: 1024            # Response length limit
  faithfulness_eval:
    temperature: 0.0            # Deterministic evaluation
    max_tokens: 10              # Short score response
  response_refine:
    temperature: 0.5            # Balanced refinement
    max_tokens: 1024            # Response length limit

  # Confidence calculation weights
  confidence_relevance_weight: 0.4   # Weight for relevance in confidence
  confidence_faithfulness_weight: 0.6 # Weight for faithfulness in confidence

# ============================================================================
# Search Tuning Parameters (v1.0.5)
# ============================================================================
# Fine-tune hybrid search behaviour
search_tuning:
  # BM25 normalisation divisor (higher = reduced score range)
  bm25_normalisation_divisor: 10.0

  # Reciprocal Rank Fusion fetch multiplier
  rrf_fetch_multiplier: 3

  # Position decay factor for relevance scoring (0.0-1.0)
  position_decay_factor: 0.9

# ============================================================================
# Processing Parameters (v1.0.5)
# ============================================================================
# Text processing and tokenisation settings
processing:
  # Maximum characters for context truncation in evaluation
  context_truncation_chars: 2000

  # Approximate characters per token for estimation
  chars_per_token_estimate: 4

  # tiktoken encoding for token counting
  token_encoding: cl100k_base

# ============================================================================
# Hardware Tier Thresholds (v1.0.5)
# ============================================================================
# Memory thresholds for tier classification (GB)
hardware_thresholds:
  minimal_max_memory_gb: 8    # Systems < 8GB are MINIMAL tier
  standard_max_memory_gb: 16  # Systems < 16GB are STANDARD tier
  high_max_memory_gb: 32      # Systems < 32GB are HIGH tier, >= 32GB are EXTREME

# ============================================================================
# Prompt Templates (v1.0.5)
# ============================================================================
# Prompts can be customised via file reference or inline content.
# Use "ragd prompts export" to create editable prompt files.
#
# File reference format:
#   prompt_name:
#     file: ~/.ragd/prompts/category/name.txt
#
# Inline format:
#   prompt_name:
#     inline: "Your custom prompt text here..."
#
# RAG prompts (answer generation)
# rag_prompts:
#   answer:
#     file: ~/.ragd/prompts/rag/answer.txt
#   summarise:
#     file: ~/.ragd/prompts/rag/summarise.txt
#   compare:
#     file: ~/.ragd/prompts/rag/compare.txt
#
# Agentic prompts (CRAG/Self-RAG)
# agentic_prompts:
#   relevance_eval:
#     file: ~/.ragd/prompts/agentic/relevance_eval.txt
#   query_rewrite:
#     file: ~/.ragd/prompts/agentic/query_rewrite.txt
#   faithfulness_eval:
#     file: ~/.ragd/prompts/agentic/faithfulness_eval.txt
#
# Metadata prompts (LLM metadata extraction)
# metadata_prompts:
#   summary:
#     file: ~/.ragd/prompts/metadata/summary.txt
#   classification:
#     file: ~/.ragd/prompts/metadata/classification.txt
#
# Evaluation prompts (quality metrics)
# evaluation_prompts:
#   faithfulness:
#     file: ~/.ragd/prompts/evaluation/faithfulness.txt
#   answer_relevancy:
#     file: ~/.ragd/prompts/evaluation/answer_relevancy.txt

# ============================================================================
# Boilerplate Patterns (v1.0.5)
# ============================================================================
# Custom patterns for boilerplate removal during HTML processing
# boilerplate:
#   custom_patterns:
#     - "^Subscribe to our newsletter$"
#     - "^Cookie preferences$"
#     - "^Copyright \\d{4}"

# ============================================================================
# Hardware Tier Profiles
# ============================================================================
# These presets are applied based on detected hardware tier.
# You can create custom presets in ~/.config/ragd/presets/
#
# Tier: minimal (<8GB RAM, CPU only)
#   embedding.model: sentence-transformers/all-MiniLM-L6-v2
#   embedding.batch_size: 8
#   chunking.target_tokens: 256
#
# Tier: standard (8-16GB RAM, integrated GPU)
#   embedding.model: BAAI/bge-base-en-v1.5
#   embedding.batch_size: 16
#   chunking.target_tokens: 400
#
# Tier: high (16-64GB RAM, dedicated GPU)
#   embedding.model: BAAI/bge-base-en-v1.5
#   embedding.batch_size: 32
#   chunking.target_tokens: 512
#
# Tier: extreme (64GB+ RAM, high-end GPU)
#   embedding.model: nomic-ai/nomic-embed-text-v1.5
#   embedding.batch_size: 64
#   chunking.target_tokens: 512
#   chunking.strategy: semantic

# ============================================================================
# Environment Variable Reference
# ============================================================================
# All configuration values can be overridden via environment variables:
#
# RAGD_VERSION=1
# RAGD_STORAGE__DATA_DIR=~/.local/share/ragd
# RAGD_STORAGE__CHROMA_DB=~/.local/share/ragd/chroma_db
# RAGD_EMBEDDING__MODEL=BAAI/bge-base-en-v1.5
# RAGD_EMBEDDING__DEVICE=auto
# RAGD_EMBEDDING__BATCH_SIZE=32
# RAGD_CHUNKING__STRATEGY=sentence
# RAGD_CHUNKING__TARGET_TOKENS=512
# RAGD_CHUNKING__OVERLAP_TOKENS=50
# RAGD_SEARCH__DEFAULT_LIMIT=10
# RAGD_OUTPUT__DEFAULT_FORMAT=rich
# RAGD_LOGGING__LEVEL=INFO

# ============================================================================
# Related Documentation
# ============================================================================
# - State-of-the-Art Configuration: docs/development/research/state-of-the-art-configuration.md
# - ADR-0013: Configuration Schema: docs/development/decisions/adrs/0013-configuration-schema.md
# - ADR-0011: Hardware Detection: docs/development/decisions/adrs/0011-hardware-detection.md
# - CLI Reference: docs/reference/cli-reference.md
